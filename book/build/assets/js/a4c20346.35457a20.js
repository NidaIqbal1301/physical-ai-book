"use strict";(globalThis.webpackChunkphysical_ai_book=globalThis.webpackChunkphysical_ai_book||[]).push([[874],{3615(e,n,i){i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>c,default:()=>p,frontMatter:()=>s,metadata:()=>r,toc:()=>a});var o=i(4848),t=i(8453);const s={title:"Voice-to-Action Systems",sidebar_label:"Voice-to-Action",sidebar_position:1,description:"Integrating OpenAI Whisper for voice processing in humanoid robots"},c="Voice-to-Action Systems",r={id:"module-4-vla/voice-action",title:"Voice-to-Action Systems",description:"Integrating OpenAI Whisper for voice processing in humanoid robots",source:"@site/docs/module-4-vla/voice-action.md",sourceDirName:"module-4-vla",slug:"/module-4-vla/voice-action",permalink:"/docs/module-4-vla/voice-action",draft:!1,unlisted:!1,editUrl:"https://github.com/your-username/physical-ai-book/tree/main/docs/module-4-vla/voice-action.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{title:"Voice-to-Action Systems",sidebar_label:"Voice-to-Action",sidebar_position:1,description:"Integrating OpenAI Whisper for voice processing in humanoid robots"},sidebar:"tutorialSidebar",previous:{title:"VLA",permalink:"/docs/module-4-vla/"},next:{title:"Cognitive Planning",permalink:"/docs/module-4-vla/cognitive-planning"}},l={},a=[{value:"Key Components",id:"key-components",level:2},{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"References",id:"references",level:2}];function d(e){const n={h1:"h1",h2:"h2",li:"li",p:"p",ul:"ul",...(0,t.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.h1,{id:"voice-to-action-systems",children:"Voice-to-Action Systems"}),"\n",(0,o.jsx)(n.p,{children:"This chapter covers integrating OpenAI Whisper for voice processing in humanoid robots, enabling voice command interpretation."}),"\n",(0,o.jsx)(n.h2,{id:"key-components",children:"Key Components"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Speech recognition with Whisper"}),"\n",(0,o.jsx)(n.li,{children:"Natural language processing"}),"\n",(0,o.jsx)(n.li,{children:"Intent extraction from voice commands"}),"\n",(0,o.jsx)(n.li,{children:"Integration with action planning systems"}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Set up voice processing pipeline for humanoid robots"}),"\n",(0,o.jsx)(n.li,{children:"Extract meaningful intents from speech"}),"\n",(0,o.jsx)(n.li,{children:"Connect voice processing to action planning systems"}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"references",children:"References"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Placeholder for references"}),"\n"]})]})}function p(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}},8453(e,n,i){i.d(n,{R:()=>c,x:()=>r});var o=i(6540);const t={},s=o.createContext(t);function c(e){const n=o.useContext(s);return o.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:c(e.components),o.createElement(s.Provider,{value:n},e.children)}}}]);