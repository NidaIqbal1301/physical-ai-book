"use strict";(globalThis.webpackChunkphysical_ai_book=globalThis.webpackChunkphysical_ai_book||[]).push([[459],{18(e,n,i){i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>t,default:()=>h,frontMatter:()=>r,metadata:()=>a,toc:()=>c});var o=i(4848),s=i(8453);const r={title:"ROS 2 - The Robotic Nervous System",sidebar_label:"ROS 2",sidebar_position:2,description:"Understanding ROS 2 as the middleware for humanoid robot control",keywords:["ROS 2","robotics middleware","humanoid robotics","robot operating system"]},t="ROS 2 - The Robotic Nervous System",a={id:"module-1-ros2/index",title:"ROS 2 - The Robotic Nervous System",description:"Understanding ROS 2 as the middleware for humanoid robot control",source:"@site/docs/module-1-ros2/index.mdx",sourceDirName:"module-1-ros2",slug:"/module-1-ros2/",permalink:"/docs/module-1-ros2/",draft:!1,unlisted:!1,editUrl:"https://github.com/your-username/physical-ai-book/tree/main/docs/module-1-ros2/index.mdx",tags:[],version:"current",sidebarPosition:2,frontMatter:{title:"ROS 2 - The Robotic Nervous System",sidebar_label:"ROS 2",sidebar_position:2,description:"Understanding ROS 2 as the middleware for humanoid robot control",keywords:["ROS 2","robotics middleware","humanoid robotics","robot operating system"]},sidebar:"tutorialSidebar",previous:{title:"Introduction",permalink:"/docs/intro"},next:{title:"ROS 2 Overview",permalink:"/docs/module-1-ros2/ros2"}},l={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Introduction to ROS 2 in Humanoid Robotics",id:"introduction-to-ros-2-in-humanoid-robotics",level:2},{value:"ROS 2 Architecture Overview",id:"ros-2-architecture-overview",level:2},{value:"Nodes: The Processing Units",id:"nodes-the-processing-units",level:3},{value:"Topics: Asynchronous Communication",id:"topics-asynchronous-communication",level:3},{value:"Services: Synchronous Request/Response",id:"services-synchronous-requestresponse",level:3},{value:"Actions: Long-Running Commands with Feedback",id:"actions-long-running-commands-with-feedback",level:3},{value:"ROS 2 Communication in Humanoid Systems",id:"ros-2-communication-in-humanoid-systems",level:2},{value:"Message Types and Custom Interfaces",id:"message-types-and-custom-interfaces",level:3},{value:"Quality of Service (QoS) Profiles",id:"quality-of-service-qos-profiles",level:3},{value:"Implementing ROS 2 for Humanoid Control",id:"implementing-ros-2-for-humanoid-control",level:2},{value:"Node Design Patterns",id:"node-design-patterns",level:3},{value:"Integration with Humanoid Middleware",id:"integration-with-humanoid-middleware",level:3},{value:"Advanced ROS 2 Concepts for Humanoid Robotics",id:"advanced-ros-2-concepts-for-humanoid-robotics",level:2},{value:"Launch Files for Complex Systems",id:"launch-files-for-complex-systems",level:3},{value:"Parameter Management",id:"parameter-management",level:3},{value:"Humanoid-Specific Considerations",id:"humanoid-specific-considerations",level:2},{value:"Real-Time Requirements",id:"real-time-requirements",level:3},{value:"Safety Architecture",id:"safety-architecture",level:3},{value:"Future Developments and Trends",id:"future-developments-and-trends",level:2},{value:"Summary",id:"summary",level:2},{value:"References",id:"references",level:2}];function d(e){const n={code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.h1,{id:"ros-2---the-robotic-nervous-system",children:"ROS 2 - The Robotic Nervous System"}),"\n",(0,o.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,o.jsx)(n.p,{children:"After completing this chapter, students will be able to:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Explain the fundamental architecture of ROS 2 and its role in humanoid robotics"}),"\n",(0,o.jsx)(n.li,{children:"Identify the key differences between ROS 1 and ROS 2"}),"\n",(0,o.jsx)(n.li,{children:"Implement basic ROS 2 concepts in Python using rclpy for humanoid robot control"}),"\n",(0,o.jsx)(n.li,{children:"Design and implement nodes, topics, services, and actions for humanoid robot applications"}),"\n",(0,o.jsx)(n.li,{children:"Evaluate the advantages of ROS 2 over ROS 1 for humanoid robot applications"}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"introduction-to-ros-2-in-humanoid-robotics",children:"Introduction to ROS 2 in Humanoid Robotics"}),"\n",(0,o.jsx)(n.p,{children:"Robot Operating System 2 (ROS 2) serves as the foundational middleware that connects the digital brain (AI models, planners) with the physical body (sensors, actuators) of humanoid robots. Unlike its predecessor ROS 1, ROS 2 addresses critical challenges in humanoid robotics including real-time performance, security, and reliability requirements for robots operating in human environments."}),"\n",(0,o.jsx)(n.p,{children:"In the context of humanoid robotics, ROS 2 provides:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Real-time capabilities"}),": Essential for maintaining balance and coordinated movement"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Security features"}),": Important for robots operating in public or sensitive environments"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Official Windows support"}),": Expanding development options"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Improved communication patterns"}),": Better suited for complex humanoid robot architectures"]}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:"The evolution from ROS 1 to ROS 2 was driven by the growing needs of advanced robotics applications, particularly humanoid robots that must operate safely and reliably in human-populated environments. ROS 2's architecture is built on the Data Distribution Service (DDS) standard, which provides more robust and configurable communication patterns essential for humanoid robot control."}),"\n",(0,o.jsx)(n.h2,{id:"ros-2-architecture-overview",children:"ROS 2 Architecture Overview"}),"\n",(0,o.jsx)(n.h3,{id:"nodes-the-processing-units",children:"Nodes: The Processing Units"}),"\n",(0,o.jsx)(n.p,{children:"In ROS 2, nodes represent individual software components that perform specific functions. For humanoid robots, nodes correspond to different subsystems:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Perception Nodes"}),": Process sensor data (cameras, LiDAR, IMUs, force/torque sensors)"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Navigation Nodes"}),": Handle path planning and obstacle avoidance"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Control Nodes"}),": Manage joint positions, velocities, and torques"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Cognitive Nodes"}),": Process high-level commands and decision-making"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Humanoid-specific Nodes"}),": Handle unique aspects of humanoid locomotion and interaction"]}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:"Each node runs in its own process space, contributing to system robustness. If one node fails, others can continue operating, which is critical for humanoid robots where complete system failure could result in unsafe situations."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"# Example of a humanoid joint controller node\nimport rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import JointState\nfrom std_msgs.msg import Float64MultiArray\n\nclass JointController(Node):\n    def __init__(self):\n        super().__init__('joint_controller')\n        self.subscription = self.create_subscription(\n            JointState,\n            'joint_states',\n            self.listener_callback,\n            10)\n        self.publisher = self.create_publisher(\n            Float64MultiArray,\n            'joint_commands',\n            10)\n        \n    def listener_callback(self, msg):\n        # Process joint state information\n        self.get_logger().info(f'Received joint states: {msg.position}')\n\ndef main(args=None):\n    rclpy.init(args=args)\n    joint_controller = JointController()\n    rclpy.spin(joint_controller)\n    joint_controller.destroy_node()\n    rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,o.jsx)(n.h3,{id:"topics-asynchronous-communication",children:"Topics: Asynchronous Communication"}),"\n",(0,o.jsx)(n.p,{children:"Topics enable asynchronous data exchange between nodes using publish-subscribe patterns. In humanoid robotics, this is essential for:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Sensor data distribution (camera feeds, IMU readings)"}),"\n",(0,o.jsx)(n.li,{children:"State publishing (joint angles, robot pose)"}),"\n",(0,o.jsx)(n.li,{children:"Command streaming (motion trajectories, actuator commands)"}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:"For humanoid robots, topics must support high-frequency updates for real-time control. For example:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Joint state updates: 100Hz or higher for smooth motion"}),"\n",(0,o.jsx)(n.li,{children:"IMU data: 200Hz for balance control"}),"\n",(0,o.jsx)(n.li,{children:"Camera data: 30-60Hz for visual processing"}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"services-synchronous-requestresponse",children:"Services: Synchronous Request/Response"}),"\n",(0,o.jsx)(n.p,{children:"Services provide synchronous request-response communication, ideal for humanoid robotics tasks that require guaranteed completion:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Trajectory execution confirmation"}),"\n",(0,o.jsx)(n.li,{children:"Calibration procedures"}),"\n",(0,o.jsx)(n.li,{children:"Diagnostic queries"}),"\n",(0,o.jsx)(n.li,{children:"Emergency stop activation"}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"actions-long-running-commands-with-feedback",children:"Actions: Long-Running Commands with Feedback"}),"\n",(0,o.jsx)(n.p,{children:"Actions are particularly important for humanoid robotics as they provide the ability to send goals, receive feedback during execution, and get results. This is essential for:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Walking pattern generation and execution"}),"\n",(0,o.jsx)(n.li,{children:"Manipulation tasks with multi-step processes"}),"\n",(0,o.jsx)(n.li,{children:"Navigation with dynamic replanning"}),"\n"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"# Example of an action server for humanoid walking\nfrom rclpy.action import ActionServer\nfrom rclpy.node import Node\nfrom your_pkg.action import Walk\n\nclass WalkActionServer(Node):\n    def __init__(self):\n        super().__init__('walk_action_server')\n        self._action_server = ActionServer(\n            self,\n            Walk,\n            'walk',\n            self.execute_callback)\n\n    def execute_callback(self, goal_handle):\n        # Execute walking behavior\n        feedback_msg = Walk.Feedback()\n        result = Walk.Result()\n        \n        # Implementation of walking logic with feedback\n        for i in range(10):\n            feedback_msg.progress = i / 10.0\n            goal_handle.publish_feedback(feedback_msg)\n        \n        result.success = True\n        return result\n"})}),"\n",(0,o.jsx)(n.h2,{id:"ros-2-communication-in-humanoid-systems",children:"ROS 2 Communication in Humanoid Systems"}),"\n",(0,o.jsx)(n.h3,{id:"message-types-and-custom-interfaces",children:"Message Types and Custom Interfaces"}),"\n",(0,o.jsx)(n.p,{children:"Humanoid robotics requires specialized message types beyond standard ROS 2 interfaces:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"sensor_msgs/JointState"}),": For joint angle, velocity, and effort information"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"geometry_msgs/WrenchStamped"}),": For force/torque sensing"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"control_msgs/JointTrajectoryController"}),": For trajectory following"]}),"\n",(0,o.jsx)(n.li,{children:"Custom messages for humanoid-specific data (e.g., center of mass, contact states)"}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:"Creating custom message definitions allows humanoid robots to communicate specialized information:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-xml",children:"# HumanoidCommand.msg\nfloat64[] joint_positions\nfloat64[] joint_velocities\nfloat64[] joint_efforts\nuint8[] contact_states\nfloat64[] com_position  # Center of mass\n"})}),"\n",(0,o.jsx)(n.h3,{id:"quality-of-service-qos-profiles",children:"Quality of Service (QoS) Profiles"}),"\n",(0,o.jsx)(n.p,{children:"For humanoid robotics, appropriate QoS settings are crucial for performance and safety:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Reliability"}),": ",(0,o.jsx)(n.code,{children:"RELIABLE"})," for critical control commands, ",(0,o.jsx)(n.code,{children:"BEST_EFFORT"})," for sensor data where some loss is acceptable"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Durability"}),": ",(0,o.jsx)(n.code,{children:"TRANSIENT_LOCAL"})," for static transforms that newly connected nodes need"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"History"}),": ",(0,o.jsx)(n.code,{children:"KEEP_LAST"})," for control commands, ",(0,o.jsx)(n.code,{children:"KEEP_ALL"})," for logging"]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"implementing-ros-2-for-humanoid-control",children:"Implementing ROS 2 for Humanoid Control"}),"\n",(0,o.jsx)(n.h3,{id:"node-design-patterns",children:"Node Design Patterns"}),"\n",(0,o.jsx)(n.p,{children:"When designing nodes for humanoid robotics, several patterns emerge:"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"State Estimation Node"}),": Combines multiple sensor inputs to determine robot state"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Subscribes to: IMU, joint encoders, force/torque sensors"}),"\n",(0,o.jsx)(n.li,{children:"Publishes: Robot state (position, velocity, acceleration)"}),"\n"]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Motion Planning Node"}),": Generates trajectories for humanoid movement"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Subscribes to: High-level goals, current state"}),"\n",(0,o.jsx)(n.li,{children:"Publishes: Joint trajectories, timing information"}),"\n"]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Safety Node"}),": Monitors system state and implements protective behaviors"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Subscribes to: All critical sensor and command topics"}),"\n",(0,o.jsx)(n.li,{children:"Publishes: Safety limits, emergency stops"}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"integration-with-humanoid-middleware",children:"Integration with Humanoid Middleware"}),"\n",(0,o.jsx)(n.p,{children:"ROS 2 serves as a middleware layer above real-time control systems. For humanoid robots, this typically involves:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Low-level Controllers"}),": Real-time control of joint positions, often implemented in C++ with high-priority processes"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"ROS 2 Interface"}),": Bridge nodes connecting ROS 2 topics to low-level interfaces"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"High-level Planning"}),": Motion planning, path planning, and behavioral logic in ROS 2"]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"advanced-ros-2-concepts-for-humanoid-robotics",children:"Advanced ROS 2 Concepts for Humanoid Robotics"}),"\n",(0,o.jsx)(n.h3,{id:"launch-files-for-complex-systems",children:"Launch Files for Complex Systems"}),"\n",(0,o.jsx)(n.p,{children:"Humanoid robots typically require multiple nodes to coordinate. ROS 2 launch files provide a mechanism to:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Start multiple nodes simultaneously"}),"\n",(0,o.jsx)(n.li,{children:"Configure node parameters"}),"\n",(0,o.jsx)(n.li,{children:"Handle dependencies between nodes"}),"\n",(0,o.jsx)(n.li,{children:"Monitor node health"}),"\n"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"# Example launch file for humanoid robot control\nfrom launch import LaunchDescription\nfrom launch_ros.actions import Node\n\ndef generate_launch_description():\n    return LaunchDescription([\n        Node(\n            package='humanoid_control',\n            executable='joint_controller',\n            name='joint_controller',\n            parameters=[\n                {'controller_frequency': 100},\n                {'robot_description': 'path/to/robot.urdf'}\n            ]\n        ),\n        Node(\n            package='humanoid_perception',\n            executable='state_estimator',\n            name='state_estimator'\n        )\n    ])\n"})}),"\n",(0,o.jsx)(n.h3,{id:"parameter-management",children:"Parameter Management"}),"\n",(0,o.jsx)(n.p,{children:"Humanoid robots require extensive parameter configuration:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Joint limits and safety constraints"}),"\n",(0,o.jsx)(n.li,{children:"Control gains for different movement types"}),"\n",(0,o.jsx)(n.li,{children:"Sensor calibration values"}),"\n",(0,o.jsx)(n.li,{children:"Walking pattern parameters"}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:"ROS 2 provides parameter servers and configuration files to manage these values effectively."}),"\n",(0,o.jsx)(n.h2,{id:"humanoid-specific-considerations",children:"Humanoid-Specific Considerations"}),"\n",(0,o.jsx)(n.h3,{id:"real-time-requirements",children:"Real-Time Requirements"}),"\n",(0,o.jsx)(n.p,{children:"Humanoid robots have stringent real-time requirements that ROS 2 addresses through:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Deadline QoS"}),": Ensuring messages are processed within time constraints"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Liveliness QoS"}),": Confirming nodes are actively processing data"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"RMW Implementation"}),": Using real-time capable middleware implementations"]}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"safety-architecture",children:"Safety Architecture"}),"\n",(0,o.jsx)(n.p,{children:"ROS 2 enables the implementation of robust safety systems for humanoid robots:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Process Isolation"}),": Nodes running in separate processes enhance system safety"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Monitoring Tools"}),": Built-in tools for monitoring node health and system performance"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Emergency Procedures"}),": Defined patterns for handling system failures safely"]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"future-developments-and-trends",children:"Future Developments and Trends"}),"\n",(0,o.jsx)(n.p,{children:"ROS 2 continues to evolve with features specifically relevant to humanoid robotics:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"ROS 2 Navigation"}),": Advanced navigation stack with improved support for legged robots"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"ROS 2 Control"}),": Enhanced control framework for complex robotic systems"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Simulation Integration"}),": Better integration with physics simulation for humanoid robots"]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,o.jsx)(n.p,{children:"ROS 2 provides the foundational communication infrastructure for humanoid robotics, enabling the integration of perception, planning, and action systems. Its architecture addresses the unique challenges of humanoid robots including real-time requirements, safety considerations, and complex multi-modal sensor integration. As humanoid robotics continues to advance, ROS 2 will remain a critical component for connecting the digital and physical aspects of these sophisticated systems."}),"\n",(0,o.jsx)(n.h2,{id:"references",children:"References"}),"\n",(0,o.jsxs)(n.p,{children:["Corrales Ram\xedrez, J. E., Candelas Her\xedas, F. A., & Torres, F. (2016). ROS and Gazebo in education and research of mobile robotics. ",(0,o.jsx)(n.em,{children:"IFAC-PapersOnLine"}),", 49(30), 54-59."]}),"\n",(0,o.jsxs)(n.p,{children:["Macenski, S., Woodall, S., & Faust, A. (2022). The Navigation2 Project: An Updated Robot Navigation System for ROS 2. ",(0,o.jsx)(n.em,{children:"IEEE Robotics & Automation Magazine"}),", 29(2), 70-78."]}),"\n",(0,o.jsxs)(n.p,{children:["Quigley, M., Gerkey, B., & Smart, W. D. (2009). Programming robots with ROS: A practical introduction to the Robot Operating System. ",(0,o.jsx)(n.em,{children:"IEEE Intelligent Systems"}),", 32(1), 28-32."]}),"\n",(0,o.jsxs)(n.p,{children:["S\xfcnderhauf, N., Neubert, P., & Protzel, P. (2018). Are we there yet? Challenging ROS2 for real-world robot applications. ",(0,o.jsx)(n.em,{children:"ROSCon"}),", 2018."]})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}},8453(e,n,i){i.d(n,{R:()=>t,x:()=>a});var o=i(6540);const s={},r=o.createContext(s);function t(e){const n=o.useContext(r);return o.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:t(e.components),o.createElement(r.Provider,{value:n},e.children)}}}]);