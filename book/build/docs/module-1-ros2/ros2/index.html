<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-module-1-ros2/ros2" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.1.0">
<title data-rh="true">ROS 2: The Robotic Nervous System | Physical AI &amp; Humanoid Robotics</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://your-username.github.io/img/placeholder-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://your-username.github.io/img/placeholder-social-card.jpg"><meta data-rh="true" property="og:url" content="https://your-username.github.io/docs/module-1-ros2/ros2"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="ROS 2: The Robotic Nervous System | Physical AI &amp; Humanoid Robotics"><meta data-rh="true" name="description" content="Learning Objectives"><meta data-rh="true" property="og:description" content="Learning Objectives"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://your-username.github.io/docs/module-1-ros2/ros2"><link data-rh="true" rel="alternate" href="https://your-username.github.io/docs/module-1-ros2/ros2" hreflang="en"><link data-rh="true" rel="alternate" href="https://your-username.github.io/docs/module-1-ros2/ros2" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.611dcb41.css">
<script src="/assets/js/runtime~main.7e41cefd.js" defer="defer"></script>
<script src="/assets/js/main.7115506d.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/placeholder-logo.svg" alt="Physical AI Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/placeholder-logo.svg" alt="Physical AI Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Physical AI Book</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/intro">Book</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/your-username/physical-ai-book" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/intro">Introduction</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" href="/docs/module-1-ros2/">Module 1 - The Robotic Nervous System (ROS 2)</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/module-1-ros2/">ROS 2</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/module-1-ros2/ros2">ROS 2 Overview</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/module-1-ros2/architecture">Architecture</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/module-1-ros2/nodes-topics-services">Nodes, Topics, Services</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/module-1-ros2/urdf">URDF</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/module-2-digital-twin/">Module 2 - The Digital Twin (Gazebo &amp; Unity)</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/module-3-ai-brain/">Module 3 - The AI-Robot Brain (NVIDIA Isaac)</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/module-4-vla/">Module 4 - Vision-Language-Action (VLA)</a></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><span class="breadcrumbs__link">Module 1 - The Robotic Nervous System (ROS 2)</span><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">ROS 2 Overview</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>ROS 2: The Robotic Nervous System</h1></header><h2 class="anchor anchorWithStickyNavbar_LWe7" id="learning-objectives">Learning Objectives<a href="#learning-objectives" class="hash-link" aria-label="Direct link to Learning Objectives" title="Direct link to Learning Objectives">​</a></h2>
<p>Upon completing this chapter, you will be able to:</p>
<ul>
<li>Articulate the role of ROS 2 as a foundational software framework in modern robotics, particularly for complex systems like humanoids.</li>
<li>Describe the core components of the ROS 2 architecture: nodes, topics, services, and actions.</li>
<li>Explain the publish-subscribe communication model and its application in robotic systems.</li>
<li>Differentiate between synchronous (service-based) and asynchronous (action-based) communication for robotic tasks.</li>
<li>Understand the function of the Unified Robot Description Format (URDF) in defining the physical structure and kinematics of a humanoid robot.</li>
<li>Relate ROS 2 concepts to the biological nervous system to form a strong conceptual model of a robot&#x27;s software architecture.</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="introduction-a-nervous-system-for-robots">Introduction: A Nervous System for Robots<a href="#introduction-a-nervous-system-for-robots" class="hash-link" aria-label="Direct link to Introduction: A Nervous System for Robots" title="Direct link to Introduction: A Nervous System for Robots">​</a></h2>
<p>A humanoid robot is an intricate fusion of hardware—motors, sensors, processors, and a mechanical chassis. However, without a sophisticated software framework to orchestrate its components, this hardware is merely a marionette without a puppeteer. The Robot Operating System (ROS) provides this orchestration. ROS 2, its modern iteration, is not a traditional operating system like Windows or Linux; it is a flexible framework of software libraries and tools designed to simplify the creation of complex and robust robot behaviors (Macenski et al., 2022).</p>
<p>For a humanoid robot, the parallels between ROS 2 and a biological nervous system are striking. ROS 2 acts as the central and peripheral nervous system, managing the flow of information and commands. Sensory data from cameras (eyes), Inertial Measurement Units (IMUs) for balance (vestibular system), and joint encoders for proprioception (somatic senses) are transmitted across the system. In response, motor commands are dispatched to actuators in the limbs. This chapter explores the fundamental components of ROS 2 that enable this complex interplay, establishing it as the veritable nervous system for the next generation of humanoid robots.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="nodes-the-brains-functional-units">Nodes: The Brain&#x27;s Functional Units<a href="#nodes-the-brains-functional-units" class="hash-link" aria-label="Direct link to Nodes: The Brain&#x27;s Functional Units" title="Direct link to Nodes: The Brain&#x27;s Functional Units">​</a></h2>
<p>In the ROS 2 ecosystem, a <strong>node</strong> is the smallest unit of computation. Each node is a process responsible for a single, well-defined task. This modular approach is a cornerstone of ROS 2&#x27;s design, promoting reusability and fault tolerance. If a node fails, it can be restarted without necessarily bringing down the entire robotic system.</p>
<p>For a humanoid robot, you might have nodes such as:</p>
<ul>
<li><code>bipedal_locomotion_planner</code>: A node that computes the gait and foot placements required to walk.</li>
<li><code>imu_sensor_publisher</code>: A node dedicated to reading data from the IMU and publishing it for other parts of the system to use for maintaining balance.</li>
<li><code>vision_perception_node</code>: A node that processes raw camera feeds to identify objects, obstacles, or people in the environment.</li>
<li><code>joint_state_controller</code>: A node that commands the individual motors in the robot&#x27;s joints (e.g., knees, elbows, fingers).</li>
</ul>
<p>Each node is an independent executable that communicates with other nodes using the ROS 2 communication protocols.</p>
<div class="language-mermaid codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-mermaid codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">graph TD</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    A[imu_sensor_publisher] --&gt;|/imu_data| B(bipedal_locomotion_planner);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    C[vision_perception_node] --&gt;|/detected_objects| B;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    B --&gt;|/joint_commands| D[joint_state_controller];</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><em>Figure 1: A simplified graph showing how different nodes in a humanoid might communicate.</em></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="topics-the-sensory-and-motor-pathways">Topics: The Sensory and Motor Pathways<a href="#topics-the-sensory-and-motor-pathways" class="hash-link" aria-label="Direct link to Topics: The Sensory and Motor Pathways" title="Direct link to Topics: The Sensory and Motor Pathways">​</a></h2>
<p>If nodes are the functional units of the brain, <strong>topics</strong> are the neural pathways that carry information between them. Topics operate on a <strong>publish-subscribe</strong> model. A node can <em>publish</em> messages to a topic, and any number of other nodes can <em>subscribe</em> to that topic to receive those messages. This is an anonymous, asynchronous communication method; the publishing node does not know which nodes (if any) are subscribed.</p>
<p>This decoupling is essential for complex systems. For example, the <code>imu_sensor_publisher</code> node does not need to know about the locomotion planner or any other specific system that needs balance information. It simply publishes the robot&#x27;s orientation and angular velocity to the <code>/imu/data</code> topic. Any node that needs this data can subscribe to it.</p>
<p>Key topics on a humanoid robot would include:</p>
<ul>
<li><code>/joint_states</code>: A topic where a node publishes the current angle, velocity, and effort of every joint, providing proprioceptive feedback.</li>
<li><code>/scan</code>: Commonly used for LiDAR data to perceive the robot&#x27;s immediate surroundings and avoid collisions.</li>
<li><code>/cmd_vel</code>: A topic where a navigation or teleoperation node can publish velocity commands to make the robot move. For a humanoid, this might be interpreted by the locomotion planner to mean &quot;walk forward at 0.5 m/s.&quot;</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="message-types">Message Types<a href="#message-types" class="hash-link" aria-label="Direct link to Message Types" title="Direct link to Message Types">​</a></h3>
<p>Every topic has a defined <strong>message type</strong>. This is the data structure for the information being sent. For example, the <code>/imu/data</code> topic might use the <code>sensor_msgs/Imu</code> message type, which has fields for orientation (as a quaternion), angular velocity, and linear acceleration. Using standardized message types ensures that nodes can correctly interpret the data being transmitted.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="services-direct-commands-and-queries">Services: Direct Commands and Queries<a href="#services-direct-commands-and-queries" class="hash-link" aria-label="Direct link to Services: Direct Commands and Queries" title="Direct link to Services: Direct Commands and Queries">​</a></h2>
<p>While topics are excellent for continuous data streams, robotics often requires direct, two-way communication. This is handled by <strong>services</strong>. A service is defined by a request-and-response pair. A <em>client</em> node sends a request to a <em>server</em> node and waits for a response. This is a synchronous transaction—the client blocks until the server has completed the task and sent back a result.</p>
<p>Services are analogous to function calls. On a humanoid, a service might be used for tasks like:</p>
<ul>
<li><code>/set_gait_mode</code>: A service where a client can request the <code>bipedal_locomotion_planner</code> to switch from a walking gait to a jogging gait. The server would respond with a boolean indicating if the switch was successful.</li>
<li><code>/get_kinematic_pose</code>: A client could request the forward kinematics for a specific limb (e.g., the right arm) given a set of joint angles. The server would perform the calculation and return the 3D pose of the end-effector.</li>
<li><code>/calibrate_sensors</code>: A service to trigger a calibration routine for the robot&#x27;s cameras or IMU.</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="actions-complex-goal-oriented-tasks">Actions: Complex, Goal-Oriented Tasks<a href="#actions-complex-goal-oriented-tasks" class="hash-link" aria-label="Direct link to Actions: Complex, Goal-Oriented Tasks" title="Direct link to Actions: Complex, Goal-Oriented Tasks">​</a></h2>
<p>Many robotic tasks are long-running and require feedback during execution. For example, telling a humanoid to &quot;walk to the kitchen&quot; is not instantaneous. The robot might take minutes to complete the task, and the requesting node might want updates on its progress or the ability to cancel the goal. This is where <strong>actions</strong> are used.</p>
<p>An action is composed of three parts:</p>
<ol>
<li><strong>Goal</strong>: The request sent by an <em>action client</em> to an <em>action server</em> (e.g., &quot;walk to coordinates X, Y&quot;).</li>
<li><strong>Feedback</strong>: The stream of updates the server provides to the client during execution (e.g., &quot;current distance to target is 3.5 meters&quot;).</li>
<li><strong>Result</strong>: The final message sent by the server upon completion (e.g., &quot;goal reached successfully&quot;).</li>
</ol>
<p>Actions are asynchronous and non-blocking. A client can send a goal and then continue with other computations, processing the feedback as it arrives. It can also send a cancellation request at any time.</p>
<p>For a humanoid, actions are critical for high-level behaviors:</p>
<ul>
<li><code>FollowPath</code>: A navigation action to make the robot traverse a series of waypoints. Feedback would include its current position along the path.</li>
<li><code>PickObject</code>: An action to command the robot to identify, approach, and grasp an object. Feedback might include the current state of the process (e.g., &quot;approaching object,&quot; &quot;opening gripper,&quot; &quot;grasping&quot;).</li>
<li><code>WaveHand</code>: A simple social interaction action.</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="urdf-the-body-schema">URDF: The Body Schema<a href="#urdf-the-body-schema" class="hash-link" aria-label="Direct link to URDF: The Body Schema" title="Direct link to URDF: The Body Schema">​</a></h2>
<p>The <strong>Unified Robot Description Format (URDF)</strong> is an XML file format used in ROS to describe all physical aspects of a robot. The URDF acts as the robot&#x27;s <em>body schema</em>—its internal model of itself. This model is fundamental for a wide range of tasks, from simulation to motion planning.</p>
<p>A URDF file defines:</p>
<ul>
<li><strong>Links</strong>: The rigid components of the robot&#x27;s body (e.g., torso, upper arm, forearm, palm). Each link has defined inertial properties (mass, moment of inertia) and visual/collision geometries.</li>
<li><strong>Joints</strong>: The connections between links. Each joint defines the kinematics of how one link moves relative to another (e.g., revolute for an elbow, prismatic for a sliding component, or fixed for a rigid connection). Joints have defined axis of rotation and motion limits.</li>
<li><strong>Sensors and Actuators</strong>: While not part of the core URDF specification, extensions like SDF (Simulation Description Format) or additional ROS plugins allow for the attachment of cameras, IMUs, and other sensors to the robot&#x27;s links.</li>
</ul>
<p>For a humanoid robot, the URDF is exceptionally complex, defining the dozens of degrees of freedom required for human-like motion. Software like RViz (ROS Visualization) can parse a URDF file to create a 3D visualization of the robot&#x27;s model, and the MoveIt! motion planning framework uses it to compute collision-free trajectories for the robot&#x27;s limbs.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="conclusion">Conclusion<a href="#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion">​</a></h2>
<p>ROS 2 provides the essential software architecture for building sophisticated robots, and its concepts are particularly well-suited for the immense complexity of humanoids. By treating nodes as functional processing centers, topics as a distributed sensory-motor network, services as direct commands, actions as goal-oriented behaviors, and URDF as the underlying body model, we can construct a robotic nervous system. This modular, message-passing architecture not only facilitates development but also creates a resilient and scalable foundation upon which advanced capabilities like bipedal locomotion, manipulation, and human-robot interaction can be built.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="references">References<a href="#references" class="hash-link" aria-label="Direct link to References" title="Direct link to References">​</a></h2>
<p>Macenski, S., Foote, T., Gerkey, B., Lalancette, C., &amp; Woodall, W. (2022). Robot Operating System 2: Design, architecture, and uses in the wild. <em>Science Robotics, 7</em>(66), eabm6074. <a href="https://doi.org/10.1126/scirobotics.abm6074" target="_blank" rel="noopener noreferrer">https://doi.org/10.1126/scirobotics.abm6074</a></p>
<p>Quigley, M., Conley, K., Gerkey, B., Faust, J., Foote, T., Leibs, J., ... &amp; Ng, A. Y. (2009). ROS: an open-source Robot Operating System. <em>In ICRA workshop on open source software</em> (Vol. 3, No. 3.2, p. 5).</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/your-username/physical-ai-book/tree/main/docs/module-1-ros2/ros2.mdx" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/module-1-ros2/"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">ROS 2</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/module-1-ros2/architecture"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Architecture</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#learning-objectives" class="table-of-contents__link toc-highlight">Learning Objectives</a></li><li><a href="#introduction-a-nervous-system-for-robots" class="table-of-contents__link toc-highlight">Introduction: A Nervous System for Robots</a></li><li><a href="#nodes-the-brains-functional-units" class="table-of-contents__link toc-highlight">Nodes: The Brain&#39;s Functional Units</a></li><li><a href="#topics-the-sensory-and-motor-pathways" class="table-of-contents__link toc-highlight">Topics: The Sensory and Motor Pathways</a><ul><li><a href="#message-types" class="table-of-contents__link toc-highlight">Message Types</a></li></ul></li><li><a href="#services-direct-commands-and-queries" class="table-of-contents__link toc-highlight">Services: Direct Commands and Queries</a></li><li><a href="#actions-complex-goal-oriented-tasks" class="table-of-contents__link toc-highlight">Actions: Complex, Goal-Oriented Tasks</a></li><li><a href="#urdf-the-body-schema" class="table-of-contents__link toc-highlight">URDF: The Body Schema</a></li><li><a href="#conclusion" class="table-of-contents__link toc-highlight">Conclusion</a></li><li><a href="#references" class="table-of-contents__link toc-highlight">References</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Book</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/intro">Introduction</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://discordapp.com/invite/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/your-username/physical-ai-book" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Physical AI & Humanoid Robotics Book. Built with ❤️ by Nida Iqbal.</div></div></div></footer></div>
</body>
</html>